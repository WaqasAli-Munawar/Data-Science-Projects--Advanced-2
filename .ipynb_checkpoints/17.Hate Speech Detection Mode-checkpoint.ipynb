{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term hate speech is understood as any type of verbal, written or behavioural communication that attacks or uses derogatory or discriminatory language against a person or group based on what they are. In other words, based on their religion, ethnicity, nationality, race, colour, ancestry, sex or another identity factor. \n",
    "\n",
    "In this file, we will work a hate speech detection model with Machine Learning and Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hate Speech Detection is generally a task of sentiment classification. So for training a model that can classify hate speech from a certain piece of text can be achieved by training it on a data that is generally used to classify sentiments. \n",
    "\n",
    "For the task of hate speech detection model, we will use the Twitter data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hate Speech Detection Model\n",
    "\n",
    "The data set we will use for the hate speech detection model consists of a **test** and **train** set. The training package includes a list of **31,962 tweets**, a corresponding **ID** and a **tag 0 or 1** for each tweet. The particular sentiment we need to detect in this dataset is whether or not the tweet is based on hate speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: (31962, 3) 31962\n",
      "Test Set: (17197, 2) 17197\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('hate_speech/train.csv')\n",
    "print(\"Training Set:\"% train.columns, train.shape, len(train))\n",
    "test = pd.read_csv('hate_speech/test.csv')\n",
    "print(\"Test Set:\"% test.columns, test.shape, len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "Data cleaning is the process of preparing incorrectly formated data for analysis by deleting or modifying the incorrectly formatted data which is generally not necessary or useful for data analysis, as it can hinder the process or provide inaccurate results. \n",
    "\n",
    "We will perform the process of data cleaning by using the `re` library in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def  clean_text(df, text_field):\n",
    "    df[text_field] = df[text_field].str.lower()\n",
    "    df[text_field] = df[text_field].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clean = clean_text(test, \"tweet\")\n",
    "train_clean = clean_text(train, \"tweet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Imbalanced data\n",
    "\n",
    "If we will deeply analyse the task we are working on with context to the data we are using, we will find that the tweets regarding hate speeches are comparatively lesser than others, so this is a situation of an unbalanced data.\n",
    "\n",
    "If we will fit this data to train our hate speech detection model, then the model will not generalize any hate speech because the data with context to the hate speech is very less than the positive ones. So in this situation, we need to prepare the data to fit properly in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of methods we can use to deal with this. One approach is to use either oversampling or downsampling. \n",
    "* In the case of oversampling, we use a function that repeatedly samples, with replacement, from the minority class until the class is the same size as the majority. \n",
    "\n",
    "Let’s see how we can handle this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "train_majority = train_clean[train_clean.label==0]\n",
    "train_minority = train_clean[train_clean.label==1]\n",
    "train_minority_upsampled = resample(train_minority, replace=True,n_samples=len(train_majority),random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    29720\n",
       "0    29720\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_upsampled = pd.concat([train_minority_upsampled, train_majority])\n",
    "train_upsampled['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Pipeline\n",
    "\n",
    "For simplicity and reproducibility of the hate speech detection model, we will use the Scikit-Learn’s pipeline with an **SGDClassifier**, before training our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "pipeline_sgd = Pipeline([('vect', CountVectorizer()),('tfidf',  TfidfTransformer()),('nb', SGDClassifier()),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training the model, let’s split the data into a training set and a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_upsampled['tweet'], train_upsampled['label'],random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s train the model and predict the results on the test set using the **F1 score** method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline_sgd.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9696605987864239"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we got an **F1 score of 0.96 percent** which is generally appreciatable. This model can now be deployed and used in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
